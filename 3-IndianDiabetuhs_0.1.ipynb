{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Diabeetus Detektur.</center></h1>\n",
    "No test data, just training data :P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image of Diabeetus Cat](https://www.dogalize.com/wp-content/uploads/2018/01/diabeetus-cat.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy\n",
    "##############################################\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "##############################################\n",
    "from matplotlib import pyplot as plt # plot datuhz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Data Prep </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = numpy.loadtxt('pima-indians-diabetes.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:,0:8] # the first 8 columns (individual stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = dataset[:,8] # the last column (ones and zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 8)\n",
      "(768,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape) # 768 rows, 8 columns (the features)\n",
    "print(Y.shape) # 768 rows, 1 column (the binary, 1-hot 'diabetes or no diabetes' label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X[0][0]) # Don't need this kind of precision. I'll drop them all down to float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.astype('float32')\n",
    "Y = Y.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note to self: matplotlib's imshow function is kinda neat- visualizes arrays\n",
    "#plt.imshow(X[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Model Creation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# INPUT LAYER. Input dimensions = # of features (e.g. sepalWidth, etc.)\n",
    "model.add(Dense(12, input_dim=8, activation='relu')) \n",
    "\n",
    "# HIDDEN LAYERS\n",
    "model.add(Dense(40, activation = 'relu'))\n",
    "model.add(Dense(80, activation = 'relu'))\n",
    "#model.add(Dropout(0.25))\n",
    "model.add(Dense(40, activation = 'relu'))\n",
    "\n",
    "# OUTPUT LAYER\n",
    "model.add(Dense(1, activation = 'sigmoid')) # 1 class with output of scale 0 to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Here's a list of different optimizer functions to test out when compiling below...</u>\n",
    "1. adam\n",
    "2. SGD (stochastic gradient descent)\n",
    "3. RMSprop (root mean squared propagation?)\n",
    "4. Adagrad\n",
    "5. Adadelta (Adaptive learning rate)\n",
    "6. Adamax\n",
    "7. Nadam (Nesterov Adam)\n",
    "\n",
    "Note: All these suckers should work out of the box. However, if you want to tweak them, you can read about their different parameters here:\n",
    "https://keras.io/optimizers/\n",
    "\n",
    "And some fairly in-depth explanations here:\n",
    "http://ruder.io/optimizing-gradient-descent/index.html#rmsprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Here's a list of different loss functions to test out. That said, recommend sticking to binary_crossentropy for this problem, since its the output is binary.</u>\n",
    "1. categorical_crossentropy\n",
    "2. sparse_categorical_crossentropy\n",
    "3. binary_crossentropy\n",
    "4. kullback_leibler_divergence\n",
    "5. poisson\n",
    "6. cosine_proximity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I haven't been able to get any loss functions to work other than sparse_categorical_crossentropy\n",
    "# All the above optimizers work, however\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='adadelta',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Train and Evaluate </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "768/768 [==============================] - 1s 766us/step - loss: 0.3679 - acc: 0.8268\n",
      "Epoch 2/150\n",
      "768/768 [==============================] - 0s 418us/step - loss: 0.3683 - acc: 0.8229\n",
      "Epoch 3/150\n",
      "768/768 [==============================] - 0s 243us/step - loss: 0.3584 - acc: 0.8307\n",
      "Epoch 4/150\n",
      "768/768 [==============================] - 0s 301us/step - loss: 0.3494 - acc: 0.8346\n",
      "Epoch 5/150\n",
      "768/768 [==============================] - 0s 259us/step - loss: 0.3502 - acc: 0.8359\n",
      "Epoch 6/150\n",
      "768/768 [==============================] - 0s 284us/step - loss: 0.3464 - acc: 0.8333\n",
      "Epoch 7/150\n",
      "768/768 [==============================] - 0s 288us/step - loss: 0.3327 - acc: 0.8359\n",
      "Epoch 8/150\n",
      "768/768 [==============================] - 0s 413us/step - loss: 0.3387 - acc: 0.8372\n",
      "Epoch 9/150\n",
      "768/768 [==============================] - 0s 493us/step - loss: 0.3378 - acc: 0.8438\n",
      "Epoch 10/150\n",
      "768/768 [==============================] - 0s 429us/step - loss: 0.3448 - acc: 0.8464\n",
      "Epoch 11/150\n",
      "768/768 [==============================] - 0s 381us/step - loss: 0.3324 - acc: 0.8490\n",
      "Epoch 12/150\n",
      "768/768 [==============================] - 0s 418us/step - loss: 0.3411 - acc: 0.8424\n",
      "Epoch 13/150\n",
      "768/768 [==============================] - 0s 325us/step - loss: 0.3297 - acc: 0.8372\n",
      "Epoch 14/150\n",
      "768/768 [==============================] - 0s 454us/step - loss: 0.3368 - acc: 0.8424\n",
      "Epoch 15/150\n",
      "768/768 [==============================] - 0s 294us/step - loss: 0.3263 - acc: 0.8464\n",
      "Epoch 16/150\n",
      "768/768 [==============================] - 0s 378us/step - loss: 0.3231 - acc: 0.8633\n",
      "Epoch 17/150\n",
      "768/768 [==============================] - 0s 430us/step - loss: 0.3321 - acc: 0.8464\n",
      "Epoch 18/150\n",
      "768/768 [==============================] - 0s 477us/step - loss: 0.3195 - acc: 0.8503\n",
      "Epoch 19/150\n",
      "768/768 [==============================] - 0s 490us/step - loss: 0.3201 - acc: 0.8607\n",
      "Epoch 20/150\n",
      "768/768 [==============================] - 0s 478us/step - loss: 0.3210 - acc: 0.8516\n",
      "Epoch 21/150\n",
      "768/768 [==============================] - 0s 403us/step - loss: 0.3259 - acc: 0.8581\n",
      "Epoch 22/150\n",
      "768/768 [==============================] - 0s 371us/step - loss: 0.3188 - acc: 0.8581\n",
      "Epoch 23/150\n",
      "768/768 [==============================] - 0s 451us/step - loss: 0.3201 - acc: 0.8503\n",
      "Epoch 24/150\n",
      "768/768 [==============================] - 0s 399us/step - loss: 0.3126 - acc: 0.8568\n",
      "Epoch 25/150\n",
      "768/768 [==============================] - 0s 464us/step - loss: 0.3087 - acc: 0.8503\n",
      "Epoch 26/150\n",
      "768/768 [==============================] - 0s 442us/step - loss: 0.3150 - acc: 0.8542\n",
      "Epoch 27/150\n",
      "768/768 [==============================] - 0s 378us/step - loss: 0.3149 - acc: 0.8581\n",
      "Epoch 28/150\n",
      "768/768 [==============================] - 0s 389us/step - loss: 0.3121 - acc: 0.8581\n",
      "Epoch 29/150\n",
      "768/768 [==============================] - 0s 412us/step - loss: 0.3129 - acc: 0.8659\n",
      "Epoch 30/150\n",
      "768/768 [==============================] - 0s 485us/step - loss: 0.3115 - acc: 0.8555\n",
      "Epoch 31/150\n",
      "768/768 [==============================] - 0s 438us/step - loss: 0.3097 - acc: 0.8633\n",
      "Epoch 32/150\n",
      "768/768 [==============================] - 0s 457us/step - loss: 0.3093 - acc: 0.8503\n",
      "Epoch 33/150\n",
      "768/768 [==============================] - 0s 537us/step - loss: 0.3011 - acc: 0.8607 0s - loss: 0.3025 - acc:\n",
      "Epoch 34/150\n",
      "768/768 [==============================] - 0s 366us/step - loss: 0.3119 - acc: 0.8581\n",
      "Epoch 35/150\n",
      "768/768 [==============================] - 0s 383us/step - loss: 0.3128 - acc: 0.8411\n",
      "Epoch 36/150\n",
      "768/768 [==============================] - 0s 411us/step - loss: 0.3049 - acc: 0.8659\n",
      "Epoch 37/150\n",
      "768/768 [==============================] - 0s 323us/step - loss: 0.3020 - acc: 0.8685\n",
      "Epoch 38/150\n",
      "768/768 [==============================] - 0s 256us/step - loss: 0.3009 - acc: 0.8568\n",
      "Epoch 39/150\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.3086 - acc: 0.8490\n",
      "Epoch 40/150\n",
      "768/768 [==============================] - 0s 368us/step - loss: 0.2951 - acc: 0.8633 0s - loss: 0.2847 - acc: 0.8\n",
      "Epoch 41/150\n",
      "768/768 [==============================] - 0s 408us/step - loss: 0.3020 - acc: 0.8724\n",
      "Epoch 42/150\n",
      "768/768 [==============================] - 0s 310us/step - loss: 0.3070 - acc: 0.8581\n",
      "Epoch 43/150\n",
      "768/768 [==============================] - 0s 324us/step - loss: 0.2870 - acc: 0.8659\n",
      "Epoch 44/150\n",
      "768/768 [==============================] - 0s 459us/step - loss: 0.3005 - acc: 0.8620\n",
      "Epoch 45/150\n",
      "768/768 [==============================] - 0s 449us/step - loss: 0.2973 - acc: 0.8659\n",
      "Epoch 46/150\n",
      "768/768 [==============================] - 0s 518us/step - loss: 0.2873 - acc: 0.8854\n",
      "Epoch 47/150\n",
      "768/768 [==============================] - 0s 466us/step - loss: 0.2869 - acc: 0.8698\n",
      "Epoch 48/150\n",
      "768/768 [==============================] - 0s 429us/step - loss: 0.2887 - acc: 0.8763\n",
      "Epoch 49/150\n",
      "768/768 [==============================] - 0s 372us/step - loss: 0.2909 - acc: 0.8724\n",
      "Epoch 50/150\n",
      "768/768 [==============================] - 0s 383us/step - loss: 0.2891 - acc: 0.8672\n",
      "Epoch 51/150\n",
      "768/768 [==============================] - 0s 265us/step - loss: 0.2894 - acc: 0.8750\n",
      "Epoch 52/150\n",
      "768/768 [==============================] - 0s 377us/step - loss: 0.2805 - acc: 0.8711\n",
      "Epoch 53/150\n",
      "768/768 [==============================] - 0s 511us/step - loss: 0.2907 - acc: 0.8646\n",
      "Epoch 54/150\n",
      "768/768 [==============================] - 0s 351us/step - loss: 0.2833 - acc: 0.8737\n",
      "Epoch 55/150\n",
      "768/768 [==============================] - 0s 227us/step - loss: 0.2860 - acc: 0.8607\n",
      "Epoch 56/150\n",
      "768/768 [==============================] - 0s 234us/step - loss: 0.2904 - acc: 0.8672\n",
      "Epoch 57/150\n",
      "768/768 [==============================] - 0s 257us/step - loss: 0.2755 - acc: 0.8750\n",
      "Epoch 58/150\n",
      "768/768 [==============================] - 0s 238us/step - loss: 0.2786 - acc: 0.8789\n",
      "Epoch 59/150\n",
      "768/768 [==============================] - 0s 231us/step - loss: 0.2863 - acc: 0.8581\n",
      "Epoch 60/150\n",
      "768/768 [==============================] - 0s 249us/step - loss: 0.2776 - acc: 0.8802\n",
      "Epoch 61/150\n",
      "768/768 [==============================] - 0s 236us/step - loss: 0.2817 - acc: 0.8698\n",
      "Epoch 62/150\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.2737 - acc: 0.8698\n",
      "Epoch 63/150\n",
      "768/768 [==============================] - 0s 210us/step - loss: 0.2800 - acc: 0.8659\n",
      "Epoch 64/150\n",
      "768/768 [==============================] - 0s 226us/step - loss: 0.2825 - acc: 0.8724\n",
      "Epoch 65/150\n",
      "768/768 [==============================] - 0s 236us/step - loss: 0.2784 - acc: 0.8724\n",
      "Epoch 66/150\n",
      "768/768 [==============================] - 0s 229us/step - loss: 0.2706 - acc: 0.8841\n",
      "Epoch 67/150\n",
      "768/768 [==============================] - 0s 214us/step - loss: 0.2737 - acc: 0.8880\n",
      "Epoch 68/150\n",
      "768/768 [==============================] - 0s 214us/step - loss: 0.2741 - acc: 0.8776\n",
      "Epoch 69/150\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.2639 - acc: 0.8737\n",
      "Epoch 70/150\n",
      "768/768 [==============================] - 0s 225us/step - loss: 0.2710 - acc: 0.8672\n",
      "Epoch 71/150\n",
      "768/768 [==============================] - 0s 229us/step - loss: 0.2706 - acc: 0.8750\n",
      "Epoch 72/150\n",
      "768/768 [==============================] - 0s 235us/step - loss: 0.2709 - acc: 0.8789\n",
      "Epoch 73/150\n",
      "768/768 [==============================] - 0s 269us/step - loss: 0.2663 - acc: 0.8711\n",
      "Epoch 74/150\n",
      "768/768 [==============================] - 0s 295us/step - loss: 0.2756 - acc: 0.8724\n",
      "Epoch 75/150\n",
      "768/768 [==============================] - 0s 274us/step - loss: 0.2698 - acc: 0.8776\n",
      "Epoch 76/150\n",
      "768/768 [==============================] - 0s 295us/step - loss: 0.2730 - acc: 0.8802\n",
      "Epoch 77/150\n",
      "768/768 [==============================] - 0s 266us/step - loss: 0.2596 - acc: 0.8945\n",
      "Epoch 78/150\n",
      "768/768 [==============================] - 0s 296us/step - loss: 0.2554 - acc: 0.8828\n",
      "Epoch 79/150\n",
      "768/768 [==============================] - 0s 288us/step - loss: 0.2568 - acc: 0.8802\n",
      "Epoch 80/150\n",
      "768/768 [==============================] - 0s 287us/step - loss: 0.2515 - acc: 0.8880\n",
      "Epoch 81/150\n",
      "768/768 [==============================] - 0s 252us/step - loss: 0.2581 - acc: 0.8880\n",
      "Epoch 82/150\n",
      "768/768 [==============================] - 0s 271us/step - loss: 0.2642 - acc: 0.8789\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 303us/step - loss: 0.2583 - acc: 0.8984\n",
      "Epoch 84/150\n",
      "768/768 [==============================] - 0s 247us/step - loss: 0.2609 - acc: 0.8789\n",
      "Epoch 85/150\n",
      "768/768 [==============================] - 0s 478us/step - loss: 0.2519 - acc: 0.8867\n",
      "Epoch 86/150\n",
      "768/768 [==============================] - 0s 281us/step - loss: 0.2641 - acc: 0.8880\n",
      "Epoch 87/150\n",
      "768/768 [==============================] - 0s 492us/step - loss: 0.2579 - acc: 0.8867\n",
      "Epoch 88/150\n",
      "768/768 [==============================] - 0s 601us/step - loss: 0.2457 - acc: 0.8932\n",
      "Epoch 89/150\n",
      "768/768 [==============================] - 0s 405us/step - loss: 0.2499 - acc: 0.8893\n",
      "Epoch 90/150\n",
      "768/768 [==============================] - 0s 381us/step - loss: 0.2541 - acc: 0.8932\n",
      "Epoch 91/150\n",
      "768/768 [==============================] - 0s 288us/step - loss: 0.2498 - acc: 0.8893\n",
      "Epoch 92/150\n",
      "768/768 [==============================] - 0s 333us/step - loss: 0.2524 - acc: 0.8867\n",
      "Epoch 93/150\n",
      "768/768 [==============================] - 0s 454us/step - loss: 0.2520 - acc: 0.8763\n",
      "Epoch 94/150\n",
      "768/768 [==============================] - 0s 368us/step - loss: 0.2393 - acc: 0.8971\n",
      "Epoch 95/150\n",
      "768/768 [==============================] - 0s 506us/step - loss: 0.2417 - acc: 0.8919\n",
      "Epoch 96/150\n",
      "768/768 [==============================] - 0s 445us/step - loss: 0.2464 - acc: 0.8893\n",
      "Epoch 97/150\n",
      "768/768 [==============================] - 0s 358us/step - loss: 0.2476 - acc: 0.8932\n",
      "Epoch 98/150\n",
      "768/768 [==============================] - 0s 423us/step - loss: 0.2414 - acc: 0.8906\n",
      "Epoch 99/150\n",
      "768/768 [==============================] - 0s 437us/step - loss: 0.2364 - acc: 0.8971\n",
      "Epoch 100/150\n",
      "768/768 [==============================] - 0s 372us/step - loss: 0.2451 - acc: 0.8971\n",
      "Epoch 101/150\n",
      "768/768 [==============================] - 0s 225us/step - loss: 0.2460 - acc: 0.8958\n",
      "Epoch 102/150\n",
      "768/768 [==============================] - 0s 234us/step - loss: 0.2584 - acc: 0.8789\n",
      "Epoch 103/150\n",
      "768/768 [==============================] - 0s 229us/step - loss: 0.2292 - acc: 0.8958\n",
      "Epoch 104/150\n",
      "768/768 [==============================] - 0s 234us/step - loss: 0.2398 - acc: 0.8906\n",
      "Epoch 105/150\n",
      "768/768 [==============================] - 0s 220us/step - loss: 0.2398 - acc: 0.8867\n",
      "Epoch 106/150\n",
      "768/768 [==============================] - 0s 242us/step - loss: 0.2262 - acc: 0.8945\n",
      "Epoch 107/150\n",
      "768/768 [==============================] - 0s 249us/step - loss: 0.2437 - acc: 0.8958\n",
      "Epoch 108/150\n",
      "768/768 [==============================] - 0s 359us/step - loss: 0.2560 - acc: 0.8880\n",
      "Epoch 109/150\n",
      "768/768 [==============================] - 0s 520us/step - loss: 0.2339 - acc: 0.8919\n",
      "Epoch 110/150\n",
      "768/768 [==============================] - 0s 222us/step - loss: 0.2279 - acc: 0.8945\n",
      "Epoch 111/150\n",
      "768/768 [==============================] - 0s 371us/step - loss: 0.2329 - acc: 0.8945\n",
      "Epoch 112/150\n",
      "768/768 [==============================] - 0s 280us/step - loss: 0.2352 - acc: 0.8958\n",
      "Epoch 113/150\n",
      "768/768 [==============================] - 0s 291us/step - loss: 0.2414 - acc: 0.8919\n",
      "Epoch 114/150\n",
      "768/768 [==============================] - 0s 293us/step - loss: 0.2255 - acc: 0.9010\n",
      "Epoch 115/150\n",
      "768/768 [==============================] - 0s 430us/step - loss: 0.2330 - acc: 0.8971\n",
      "Epoch 116/150\n",
      "768/768 [==============================] - 0s 473us/step - loss: 0.2295 - acc: 0.8880\n",
      "Epoch 117/150\n",
      "768/768 [==============================] - 0s 460us/step - loss: 0.2201 - acc: 0.9010\n",
      "Epoch 118/150\n",
      "768/768 [==============================] - 0s 502us/step - loss: 0.2347 - acc: 0.8880\n",
      "Epoch 119/150\n",
      "768/768 [==============================] - 0s 489us/step - loss: 0.2326 - acc: 0.8945\n",
      "Epoch 120/150\n",
      "768/768 [==============================] - 0s 312us/step - loss: 0.2210 - acc: 0.8971\n",
      "Epoch 121/150\n",
      "768/768 [==============================] - ETA: 0s - loss: 0.2333 - acc: 0.892 - 0s 396us/step - loss: 0.2312 - acc: 0.8945\n",
      "Epoch 122/150\n",
      "768/768 [==============================] - 0s 502us/step - loss: 0.2268 - acc: 0.8984\n",
      "Epoch 123/150\n",
      "768/768 [==============================] - 0s 500us/step - loss: 0.2226 - acc: 0.9049\n",
      "Epoch 124/150\n",
      "768/768 [==============================] - 0s 380us/step - loss: 0.2243 - acc: 0.8893\n",
      "Epoch 125/150\n",
      "768/768 [==============================] - 0s 257us/step - loss: 0.2220 - acc: 0.8984\n",
      "Epoch 126/150\n",
      "768/768 [==============================] - 0s 272us/step - loss: 0.2156 - acc: 0.9076 0s - loss: 0.2167 - acc: 0.907\n",
      "Epoch 127/150\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.2252 - acc: 0.8997\n",
      "Epoch 128/150\n",
      "768/768 [==============================] - 0s 219us/step - loss: 0.2176 - acc: 0.9036\n",
      "Epoch 129/150\n",
      "768/768 [==============================] - 0s 201us/step - loss: 0.2097 - acc: 0.9089\n",
      "Epoch 130/150\n",
      "768/768 [==============================] - 0s 196us/step - loss: 0.2139 - acc: 0.9023\n",
      "Epoch 131/150\n",
      "768/768 [==============================] - 0s 192us/step - loss: 0.2140 - acc: 0.9076\n",
      "Epoch 132/150\n",
      "768/768 [==============================] - 0s 217us/step - loss: 0.2181 - acc: 0.9089\n",
      "Epoch 133/150\n",
      "768/768 [==============================] - 0s 372us/step - loss: 0.2208 - acc: 0.8958\n",
      "Epoch 134/150\n",
      "768/768 [==============================] - 0s 305us/step - loss: 0.2101 - acc: 0.9141\n",
      "Epoch 135/150\n",
      "768/768 [==============================] - 0s 329us/step - loss: 0.2043 - acc: 0.9115\n",
      "Epoch 136/150\n",
      "768/768 [==============================] - 0s 351us/step - loss: 0.2166 - acc: 0.9089\n",
      "Epoch 137/150\n",
      "768/768 [==============================] - 0s 334us/step - loss: 0.2055 - acc: 0.9128\n",
      "Epoch 138/150\n",
      "768/768 [==============================] - 0s 349us/step - loss: 0.2259 - acc: 0.9089\n",
      "Epoch 139/150\n",
      "768/768 [==============================] - 0s 289us/step - loss: 0.2046 - acc: 0.9102\n",
      "Epoch 140/150\n",
      "768/768 [==============================] - 0s 410us/step - loss: 0.1998 - acc: 0.9102\n",
      "Epoch 141/150\n",
      "768/768 [==============================] - 0s 344us/step - loss: 0.2082 - acc: 0.9036\n",
      "Epoch 142/150\n",
      "768/768 [==============================] - 0s 348us/step - loss: 0.2104 - acc: 0.9049\n",
      "Epoch 143/150\n",
      "768/768 [==============================] - 0s 383us/step - loss: 0.2078 - acc: 0.9115\n",
      "Epoch 144/150\n",
      "768/768 [==============================] - 0s 363us/step - loss: 0.2121 - acc: 0.8932\n",
      "Epoch 145/150\n",
      "768/768 [==============================] - 0s 377us/step - loss: 0.2041 - acc: 0.9141\n",
      "Epoch 146/150\n",
      "768/768 [==============================] - 0s 342us/step - loss: 0.2153 - acc: 0.9180\n",
      "Epoch 147/150\n",
      "768/768 [==============================] - 0s 294us/step - loss: 0.2026 - acc: 0.9167\n",
      "Epoch 148/150\n",
      "768/768 [==============================] - 0s 315us/step - loss: 0.2021 - acc: 0.9128\n",
      "Epoch 149/150\n",
      "768/768 [==============================] - 0s 291us/step - loss: 0.2128 - acc: 0.9036\n",
      "Epoch 150/150\n",
      "768/768 [==============================] - 0s 293us/step - loss: 0.1998 - acc: 0.9154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fee99ad2d30>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y,\n",
    "         batch_size=15, epochs=150, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 291us/step\n",
      "loss: 0.252385047575\n",
      "accuracy: 0.889322916667\n"
     ]
    }
   ],
   "source": [
    "# Evaluate how well the training went\n",
    "scores = model.evaluate(X,Y)\n",
    "# this returns 2 elements: the 1st is loss, the 2nd is accuracy\n",
    "print('loss: '+ str(scores[0]))\n",
    "print('accuracy: '+ str(scores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out the NN's predictions for each item\n",
    "predictions = model.predict(X)\n",
    "rounded = [round(item[0]) for item in predictions] # round the results to whole numbers\n",
    "rounded[0] # here's the first one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b>Now I'll feed it a made-up array to simulate new data for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hand-jam some stats\n",
    "newIndian = [1,85,66,29,0,26.6,0.351,31] # no diabetes\n",
    "#newIndian = [6,148,72,35,0,33.6,0.627,50] # diabetes. This is input # 1 of training data\n",
    "\n",
    "# Convert that to a numpy array\n",
    "newIndian = numpy.asarray(newIndian)\n",
    "newIndian = newIndian.astype('float32')\n",
    "\n",
    "# The predict function is expecting an array with 2 dimensions:\n",
    "# (num_instances, features). However this array only holds the features.\n",
    "# Time to address this:\n",
    "newIndian = numpy.expand_dims(newIndian, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSAQIbibHKFT2TPusFUmlrwT3PNqJN42dOSFEbMo3hSv6msRDya4Q\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No diabeetus. Aw mann...\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "diabeetus = Image(url= \"data:image/jpeg;base64,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\")\n",
    "no_diabeetus = Image(url= \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSAQIbibHKFT2TPusFUmlrwT3PNqJN42dOSFEbMo3hSv6msRDya4Q\")\n",
    "\n",
    "newPredictions = model.predict(newIndian)\n",
    "rounded = round(newPredictions[0][0])\n",
    "# Digging down into the array wrapped in an array and rounding to nearest int\n",
    "if rounded == 0.0:\n",
    "    display(no_diabeetus)\n",
    "    print(\"No diabeetus. Aw mann...\")\n",
    "    \n",
    "else:\n",
    "    display(diabeetus)\n",
    "    print(\"You've got diabeetus. Hooray!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Want to save the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('diabeetus_DNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
